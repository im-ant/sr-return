defaults:
  - optim: adam_jax_dqn
  - agent: dqn_nature_rainbow
experiment:
  log_interval: 1e3
  save_interval: 1e5  # save per 100k steps
  eval_interval: 1e5  # eval per 100k steps
training:
  seed: 1
  max_steps: 2e7
  discount: 0.99
  history_length: 4
  target_network_update_freq: 8000  # 10000 in original, 8000 in Rainbow
  exploration_steps: 20000  # 50,000 in original, 20,000 in Rainbow
  double_q: False
  async_actor: False
  random_action_schedule:
    start: 1.0
    end: 0.01
    steps: 250000  # 1,000,000 in original; 250,000 in Rainbow?
env:
  game: 'BreakoutNoFrameskip-v4'  # BreakoutNoFrameskip-v4, MsPacmanNoFrameskip-v4
agent:
  cls_string: 'DQNAgent'
  kwargs: {}
network:
  cls_string: 'VanillaNet'
  kwargs: {}
replay_buffer:
  kwargs:
    memory_size: 1e6
    batch_size: 32
    n_step: 1
  asynch: False
optim:
  sgd_update_frequency: 4
  gradient_clip: 5
  kwargs: {}
